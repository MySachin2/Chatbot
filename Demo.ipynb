{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn import linear_model\n",
    "import gensim\n",
    "import operator\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer,OneHotEncoder\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances,euclidean_distances,jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i want to know you good</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>define yourself</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe yourself</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          context  \\\n",
       "0  tell me about your personality   \n",
       "1         i want to know you good   \n",
       "2                 define yourself   \n",
       "3               describe yourself   \n",
       "4          tell me about yourself   \n",
       "\n",
       "                                        response  \n",
       "0    Just think of me as the ace up your sleeve.  \n",
       "1  I can help you work smarter instead of harder  \n",
       "2    Just think of me as the ace up your sleeve.  \n",
       "3    Just think of me as the ace up your sleeve.  \n",
       "4    Just think of me as the ace up your sleeve.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the DataFrame for response\n",
    "df = pd.read_csv('dialog_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.183543  ,  0.51169   ,  0.141594  , ..., -0.08579808,\n",
       "        -0.04257199,  0.725074  ],\n",
       "       [ 0.14366301,  0.17370317,  0.1059045 , ..., -0.08443283,\n",
       "        -0.06526467,  0.68887667],\n",
       "       [-0.05459   , -0.0749    ,  0.08115001, ..., -0.12484501,\n",
       "         0.3078965 ,  0.661035  ],\n",
       "       ...,\n",
       "       [ 0.6243306 , -0.24323   ,  0.13598   , ..., -0.42309999,\n",
       "        -0.07090433,  0.10501   ],\n",
       "       [ 0.34527499,  0.10816088,  0.00393126, ..., -0.308125  ,\n",
       "        -0.02529137,  0.20571   ],\n",
       "       [ 0.33720036,  0.1136714 ,  0.1968034 , ..., -0.16597879,\n",
       "        -0.2729478 ,  0.00450979]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading for Pickles\n",
    "model_vector = np.load('models/word2vec.npy')\n",
    "model_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GloVe for Converting Question Vector\n",
    "word_vector_path = \"glove.6B.50d.txt\"\n",
    "vector_dim = 50\n",
    "word_vector = gensim.models.KeyedVectors.load_word2vec_format(word_vector_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for text normalization\n",
    "class Normalize():\n",
    "    def __init__(self, sentences):\n",
    "        '''\n",
    "        Takes a Dataframe as the input. ALl columns should contain text or atleast the ones you wish to preprocess\n",
    "        '''\n",
    "        if isinstance(sentences, pd.DataFrame):\n",
    "            self.dataframe = sentences.copy()\n",
    "        else:\n",
    "            self.dataframe = pd.DataFrame([])\n",
    "        \n",
    "    \n",
    "    def replace_characters(self, string, characters = '''[<>\\[\\/]-_'.?()]'''):\n",
    "        '''\n",
    "        Replace characters in a string given by `characters` parameter and returns the text with replaced string\n",
    "        '''\n",
    "        for char in characters:\n",
    "            string = string.replace(char, '')    \n",
    "        return string\n",
    "    \n",
    "    def lemmatize_string(self,sentence):\n",
    "        '''\n",
    "        Replace all words in a sentence by its lemma using Part-of-Speech Tags\n",
    "        '''\n",
    "        lemmas = []\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        for word,tag in nltk.pos_tag(sentence.split()):\n",
    "            if tag.startswith('N'): #Noun\n",
    "                pos_character = 'n'\n",
    "            elif tag.startswith('V'): #Verb\n",
    "                pos_character = 'v'\n",
    "            elif tag.startswith('J'): #Adjective\n",
    "                pos_character = 'a'\n",
    "            elif tag.startswith('R'): #Adverb\n",
    "                pos_character = 'r'\n",
    "            else:\n",
    "                 pos_character = 'v'    \n",
    "            lemma = lemmatizer.lemmatize(word, pos=pos_character)\n",
    "            if pos_character == 'r' and lemma==word:\n",
    "                lemma = lemmatizer.lemmatize(word, pos='a')\n",
    "            lemmas.append(lemma)\n",
    "        return ' '.join(lemmas)\n",
    "    \n",
    "    def lowercase(self, string):\n",
    "        '''\n",
    "        Convert each string to lowercase\n",
    "        '''\n",
    "        return string.lower()\n",
    "    \n",
    "    def remove_stopwords_string(self, sentence):\n",
    "        '''\n",
    "        Removes all stop words of the sentence using NLTK default English stopwords\n",
    "        '''\n",
    "        words = []\n",
    "        stop_words = list(set(stopwords.words('english')))\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word not in stop_words:\n",
    "                words.append(word)\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    def lemmatize(self, columns, inplace=False):\n",
    "        '''\n",
    "        Lemmatize the columns of the dataframe and returns it\n",
    "        `columns`: List of columns\n",
    "        `inplace`: If True, do operation inplace and return None.\n",
    "        '''\n",
    "        dataframe = self.dataframe.copy()\n",
    "        for column in columns:\n",
    "            dataframe[column] = dataframe[column].apply(self.lemmatize_string)\n",
    "        if inplace:\n",
    "            self.dataframe = dataframe.copy()\n",
    "        return dataframe\n",
    "    \n",
    "\n",
    "        \n",
    "    def remove_stopwords(self, columns, inplace=False):\n",
    "        '''\n",
    "        Removes the stopwords of the dataframe and returns it\n",
    "        `columns`: List of columns\n",
    "        `inplace`: If True, do operation inplace and return None.\n",
    "        '''\n",
    "        dataframe = self.dataframe.copy()\n",
    "        for column in columns:\n",
    "            dataframe[column] = dataframe[column].apply(self.remove_stopwords_string)\n",
    "        if inplace:\n",
    "            self.dataframe = dataframe.copy()\n",
    "        return dataframe\n",
    "    \n",
    "    def remove_special_characters(self, columns, inplace=False):\n",
    "        '''\n",
    "        Removes the special characters of the dataframe and returns it\n",
    "        `columns`: List of columns\n",
    "        `inplace`: If True, do operation inplace and return None.\n",
    "        '''\n",
    "        dataframe = self.dataframe.copy()\n",
    "        for column in columns:\n",
    "            dataframe[column] = dataframe[column].apply(self.replace_characters)\n",
    "        if inplace:\n",
    "            self.dataframe = dataframe.copy()\n",
    "        return dataframe\n",
    "    \n",
    "    def convert_to_lowercase(self, columns, inplace=False):\n",
    "        '''\n",
    "        Converts the sentences of the dataframe and returns it\n",
    "        `columns`: List of columns\n",
    "        `inplace`: If True, do operation inplace and return None.\n",
    "        '''\n",
    "        dataframe = self.dataframe.copy()\n",
    "        for column in columns:\n",
    "            dataframe[column] = dataframe[column].apply(self.lowercase)\n",
    "        if inplace:\n",
    "            self.dataframe = dataframe.copy()\n",
    "        return dataframe\n",
    "    \n",
    "    def preprocess_string(self, string):\n",
    "        '''\n",
    "        Does the following steps\n",
    "        1. Convert to lowercase\n",
    "        2. Replace all special characters (default characters)\n",
    "        3. Lemmatize all words by their POS tags\n",
    "        '''\n",
    "        lower = self.lowercase(string)\n",
    "        replaced = self.replace_characters(lower)\n",
    "        lemmatized = self.lemmatize_string(replaced)\n",
    "        return lemmatized\n",
    "    \n",
    "    def preprocess(self, columns, inplace=False):\n",
    "        '''\n",
    "        Preprocesses the sentences of the dataframe and returns it\n",
    "        `columns`: List of columns\n",
    "        `inplace`: If True, do operation inplace and return None.\n",
    "        '''\n",
    "        dataframe = self.dataframe.copy()\n",
    "        for column in columns:\n",
    "            dataframe[column] = dataframe[column].apply(self.preprocess_string)\n",
    "        if inplace:\n",
    "            self.dataframe = dataframe.copy()\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(word2vec_dict, sentence):\n",
    "    '''\n",
    "    Function to calculate the average vector of a sentence.\n",
    "    '''\n",
    "    words = sentence.split()\n",
    "    count = 0\n",
    "    # Initialize vector with all zeroes\n",
    "    vector = np.zeros(50)\n",
    "    for word in words:\n",
    "        # Add the word vector of each word to our final vector\n",
    "        try:\n",
    "            vector = vector + word2vec_dict[word]\n",
    "            count+=1\n",
    "        except KeyError: # If unknown word occurs, decrement the count\n",
    "            count-=1\n",
    "    if count==0: # Sometimes, count will be zero when every word in sentence is unknown, so then return vector\n",
    "        return vector\n",
    "    return vector/float(count) # Return mean of our vector\n",
    "\n",
    "def get_response(question, threshold=0.5):\n",
    "    '''\n",
    "    Function to return response for a question\n",
    "    '''\n",
    "    question_vector = vectorize_sentence(word_vector, question)\n",
    "    cosine_similarities = 1 - pairwise_distances([question_vector],model_vector, metric='cosine')[0]\n",
    "    responses = df['response']\n",
    "    dataframe_values = list(zip(cosine_similarities, responses))\n",
    "    similarity_df = pd.DataFrame(dataframe_values, columns=['similarity', 'response'])\n",
    "    thresholded_df = similarity_df[similarity_df['similarity'] > threshold]\n",
    "    thresholded_df_sorted = thresholded_df.sort_values(by='similarity', ascending=False)\n",
    "    response = thresholded_df_sorted.iloc[0]['response']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a question:  hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hey!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = input('Type a question: ')\n",
    "normalize = Normalize([])\n",
    "question_preprocessed = normalize.preprocess_string(question)\n",
    "get_response(question_preprocessed, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
